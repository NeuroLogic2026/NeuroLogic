{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "history_visible": true,
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "zAN00IWPlFze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U \"fsspec<2024\""
      ],
      "metadata": {
        "id": "4oXyGArgfgCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y dataset banal alembic\n",
        "!pip install -U \"SQLAlchemy>=2.0\"\n",
        "!pip install -U datasets \"fsspec<2024\"\n"
      ],
      "metadata": {
        "id": "BdskH5uCfun9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Models and Dataset**"
      ],
      "metadata": {
        "id": "B5yJEYzxPOWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    DataCollatorWithPadding,\n",
        ")\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "\n",
        "MODEL_ID = \"philschmid/DistilBERT-tweet-eval-emotion\"\n",
        "DEVICE = \"cuda\"\n",
        "BATCH_SIZE = 64\n",
        "MAX_LEN = 512\n",
        "\n",
        "# dataset\n",
        "ds_train = load_dataset(\"tweet_eval\", \"emotion\", split=\"train\")\n",
        "\n",
        "ds_train = load_dataset(\"tweet_eval\", \"emotion\", split=\"train\")\n",
        "ds_val = load_dataset(\"tweet_eval\", \"emotion\", split=\"validation\")\n",
        "\n",
        "ds_train = concatenate_datasets([ds_train, ds_val])\n",
        "\n",
        "\n",
        "# tokenize\n",
        "tok = AutoTokenizer.from_pretrained(MODEL_ID)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    enc = tok(\n",
        "        [x[\"text\"] for x in batch],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=MAX_LEN,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    enc[\"labels\"] = torch.tensor([x[\"label\"] for x in batch])\n",
        "    return enc\n",
        "\n",
        "# dataloder\n",
        "train_loader = DataLoader(\n",
        "    ds_train,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn,\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    load_dataset(\"tweet_eval\", \"emotion\", split=\"test\"),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn,\n",
        ")\n",
        "\n",
        "# model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_ID).to(DEVICE).eval()\n"
      ],
      "metadata": {
        "id": "ITHbv4rPVU1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install alibi"
      ],
      "metadata": {
        "id": "OOppurCXdSdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"spacy<3.6\""
      ],
      "metadata": {
        "id": "wVtdaV_HiEKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U \"spacy>=3.8,<3.9\" \"alibi==0.9.6\""
      ],
      "metadata": {
        "id": "_7DMaygKimeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1 (Purity)"
      ],
      "metadata": {
        "id": "tx9fkDzc70GZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Activation Visualization**"
      ],
      "metadata": {
        "id": "atj8Qg64xhdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "@torch.no_grad()\n",
        "def plot_neuron_hist(\n",
        "    model,\n",
        "    dataloader: DataLoader,\n",
        "    hook_module: torch.nn.Module,\n",
        "    neuron_idx: int,\n",
        "    class_id: int,\n",
        "    threshold: float,\n",
        "    *,\n",
        "    apply_gelu: bool = False,\n",
        "    device: str = \"cuda\",\n",
        "    bins: int = 50,\n",
        "    layer: int = 5,\n",
        "):\n",
        "    activ = []\n",
        "\n",
        "    def save_hook(_, __, out):\n",
        "        out = F.gelu(out) if apply_gelu else out\n",
        "        activ.append(out[:, 0, neuron_idx].cpu())\n",
        "\n",
        "    h = hook_module.register_forward_hook(save_hook)\n",
        "    model.eval()\n",
        "\n",
        "    y_all = []\n",
        "    for batch in dataloader:\n",
        "        # for every batch get labels and run inference\n",
        "        labels = batch.pop(\"labels\")\n",
        "        y_all.append(labels.cpu())\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        model(**batch)\n",
        "\n",
        "    h.remove()\n",
        "    y_all = torch.cat(y_all)\n",
        "    activ = torch.cat(activ)\n",
        "\n",
        "    pos = activ[y_all == class_id].numpy()\n",
        "    neg = activ[y_all != class_id].numpy()\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.axvline(threshold, color=\"k\", linestyle=\"--\", linewidth=1.5,\n",
        "              label=f\"Threshold = {threshold:.3f}\")\n",
        "    plt.hist(pos, bins=bins, alpha=0.9, label=f\"Class {class_id}\", density=True)\n",
        "    plt.hist(neg, bins=bins, alpha=0.9, label=\"Others\", density=True)\n",
        "    plt.title(f\"Activation values for Neuron({neuron_idx}, {layer})\")\n",
        "    plt.xlabel(\"Activation Value\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "qmD5J9ITxgwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Purity (Step 1)**"
      ],
      "metadata": {
        "id": "fkBswWKXIALJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from typing import Dict, List, Tuple, Callable\n",
        "\n",
        "\n",
        "def extract_predicates_rules_cls_purity_any(\n",
        "    model,\n",
        "    dataloader: DataLoader,\n",
        "    target_layer: torch.nn.Module,\n",
        "    apply_act: bool = False,\n",
        "    k: int = 15,\n",
        "    search_steps: int = 30,\n",
        "    device: str = \"cuda\",\n",
        ") -> Tuple[Dict[int, List[Tuple[int, float]]], Tuple[int, int, float]]:\n",
        "    \"\"\"\n",
        "    Picks k neurons with highest purity per class and returns\n",
        "    (neuron‑index, threshold, support) lists plus the single best neuron.\n",
        "    \"\"\"\n",
        "    z_list, y_list = [], []\n",
        "\n",
        "    # collect activations\n",
        "    def hook_fn(_, __, out):\n",
        "        z_list.append(out.detach().cpu())\n",
        "\n",
        "    h = target_layer.register_forward_hook(hook_fn)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            labels = batch.pop(\"labels\")\n",
        "            y_list.append(labels.cpu())\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            model(**batch)\n",
        "\n",
        "    h.remove()\n",
        "\n",
        "    z_all = torch.cat(z_list)\n",
        "    if apply_act:\n",
        "        gelu: Callable = getattr(model.config, \"activation_fn\", torch.nn.functional.gelu)\n",
        "        z_all = gelu(z_all)\n",
        "\n",
        "    # CLS token is first position\n",
        "    z_cls = z_all[:, 0, :] if z_all.dim() == 3 else z_all\n",
        "    y_all = torch.cat(y_list)\n",
        "\n",
        "    num_classes, hidden_size = model.config.num_labels, z_cls.shape[1]\n",
        "    purity   = torch.empty(num_classes, hidden_size)\n",
        "    thr_mat  = torch.empty(num_classes, hidden_size)\n",
        "    supp_mat = torch.empty(num_classes, hidden_size, dtype=torch.long)\n",
        "\n",
        "    # per class counts (avoid the recomputation)\n",
        "    class_counts = torch.bincount(y_all, minlength=num_classes)\n",
        "\n",
        "    for j in range(hidden_size):\n",
        "        a = z_cls[:, j]\n",
        "        idx = torch.argsort(a, descending=True)\n",
        "        a_sorted = a[idx]\n",
        "        y_sorted = y_all[idx]\n",
        "\n",
        "        # pre compute cumulative sums for every class\n",
        "        one_hot = torch.nn.functional.one_hot(y_sorted, num_classes=num_classes).cumsum(0)\n",
        "        total_seen = torch.arange(1, len(a_sorted) + 1, dtype=torch.long)\n",
        "\n",
        "        for c in range(num_classes):\n",
        "            tp = one_hot[:, c]  # positives >= threshold\n",
        "            fp = total_seen - tp  # negatives >= threshold\n",
        "            tn = (z_cls.size(0) - class_counts[c]) - fp\n",
        "\n",
        "            tp_rate = tp.float() / class_counts[c].clamp_min(1)\n",
        "            tn_rate = tn.float() / (class_counts.sum() - class_counts[c]).clamp_min(1)\n",
        "            p_scores = tp_rate + tn_rate # get purity score\n",
        "            best_idx = torch.argmax(p_scores)\n",
        "            purity[c, j]  = p_scores[best_idx]\n",
        "            thr_mat[c, j] = a_sorted[best_idx].item()\n",
        "            supp_mat[c, j] = total_seen[best_idx].item()\n",
        "\n",
        "    rules: Dict[int, List[Tuple[int, float]]] = {}\n",
        "    best_c, best_j = divmod(purity.argmax().item(), hidden_size)\n",
        "    best_val = purity[best_c, best_j].item()\n",
        "    best_neuron = (\n",
        "        best_c,\n",
        "        best_j,\n",
        "        thr_mat[best_c, best_j].item(),\n",
        "        best_val,\n",
        "        supp_mat[best_c, best_j].item(),\n",
        "    )\n",
        "    # sort and get best\n",
        "    for c in range(num_classes):\n",
        "        topk = torch.topk(purity[c], k=min(k, hidden_size))\n",
        "        indices = topk.indices.tolist()\n",
        "        rules[c] = [(j, thr_mat[c, j].item(), supp_mat[c, j].item()) for j in indices]\n",
        "\n",
        "    return rules, best_neuron\n"
      ],
      "metadata": {
        "id": "82qK3E-zK3u2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2 (Distillation)"
      ],
      "metadata": {
        "id": "EFPV-DTDZ-8n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Distillation from tree**"
      ],
      "metadata": {
        "id": "XFei5JDCPFgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# helpers\n",
        "import itertools\n",
        "def _dedup_preserve_order(seq):\n",
        "    seen = set()\n",
        "    out  = []\n",
        "    for x in seq:\n",
        "        if x not in seen:\n",
        "            seen.add(x)\n",
        "            out.append(x)\n",
        "    return out\n",
        "\n",
        "\n",
        "def _tree_to_dnf_multiclass(tree: DecisionTreeClassifier,\n",
        "                            preds: List[Predicate]) -> DNFRuleSet:\n",
        "    \"\"\"\n",
        "    Convert a multiclass decision‑tree into per‑class DNF rule‑sets.\n",
        "    Each clause is a list[Literal] (neuron‑idx, threshold, sign).\n",
        "    \"\"\"\n",
        "    T = tree.tree_\n",
        "    dnfs: DNFRuleSet = {c: [] for c in range(tree.n_classes_)}\n",
        "\n",
        "    def walk(node: int, path: List[Literal]) -> None:\n",
        "        if T.feature[node] != _tree.TREE_UNDEFINED:\n",
        "            f_idx   = T.feature[node]\n",
        "            neuron, thr, *_ = preds[f_idx]\n",
        "            walk(T.children_left[node],  path + [(neuron, thr, 0)]) # <= thr\n",
        "            walk(T.children_right[node], path + [(neuron, thr, 1)]) # > thr\n",
        "        else: # leaf => add clause\n",
        "            cls = np.argmax(T.value[node])\n",
        "            dnfs[cls].append(path)\n",
        "\n",
        "    walk(0, [])\n",
        "    return dnfs\n",
        "\n",
        "\n",
        "def _eval_predicates_matrix(X: np.ndarray, preds: List[Predicate]) -> np.ndarray:\n",
        "    if not preds:\n",
        "        return np.empty((X.shape[0], 0), dtype=bool)\n",
        "    idxs = np.fromiter((p[0] for p in preds), int)\n",
        "    thrs = np.fromiter((p[1] for p in preds), float)\n",
        "    return X[:, idxs] > thrs\n",
        "\n",
        "\n",
        "# main functions\n",
        "\n",
        "def distil_to_dnfs_from_loader(\n",
        "    model: torch.nn.Module,\n",
        "    dataloader,\n",
        "    predicates: Dict[int, List[Predicate]],\n",
        "    target_layer: torch.nn.Module,\n",
        "    *,\n",
        "    apply_act: bool = False,\n",
        "    device: str = \"cuda\",\n",
        "    max_depth: int | None = None,\n",
        "    min_samples_leaf: int = 1,\n",
        ") -> DNFRuleSet:\n",
        "    \"\"\"\n",
        "    Distil a single multiclass decision tree into per‑class DNF clauses.\n",
        "    \"\"\"\n",
        "    # collect hidden layer activations + labels\n",
        "    buf, acts_list, labels_list = [], [], []\n",
        "\n",
        "    def _hook(_, __, out): buf.append(out.detach())\n",
        "\n",
        "    h = target_layer.register_forward_hook(_hook)\n",
        "    act_fn = torch.nn.functional.gelu if apply_act else (lambda x: x)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            labels = batch.pop(\"labels\").to(\"cpu\")\n",
        "            batch  = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "            buf.clear()\n",
        "            model(**batch)\n",
        "            acts = act_fn(buf.pop().to(\"cpu\"))\n",
        "\n",
        "            if acts.dim() == 3: # take CLS token\n",
        "                acts = acts[:, 0, :]\n",
        "\n",
        "            acts_list.append(acts.numpy())\n",
        "            labels_list.append(labels.numpy())\n",
        "\n",
        "    h.remove()\n",
        "\n",
        "    X = np.concatenate(acts_list, axis=0)\n",
        "    y = np.concatenate(labels_list, axis=0)\n",
        "\n",
        "    # build global predicate set\n",
        "    all_preds = _dedup_preserve_order(\n",
        "        list(itertools.chain.from_iterable(predicates.values()))\n",
        "    )\n",
        "\n",
        "    X_bin = _eval_predicates_matrix(X, all_preds).astype(int)\n",
        "\n",
        "    # fit multiclass decision tree\n",
        "    tree = DecisionTreeClassifier(\n",
        "        max_depth=max_depth,\n",
        "        min_samples_leaf=min_samples_leaf,\n",
        "        random_state=0,\n",
        "    ).fit(X_bin, y)\n",
        "\n",
        "    # convert tree => per‑class DNF\n",
        "    dnfs = _tree_to_dnf_multiclass(tree, all_preds)\n",
        "    return dnfs"
      ],
      "metadata": {
        "id": "uwW8N1f5CLfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Simple positive destillation**"
      ],
      "metadata": {
        "id": "Vf3kCPbdPIUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict, Counter\n",
        "from typing import Dict, List, Tuple, FrozenSet, Callable, Set\n",
        "import torch\n",
        "\n",
        "def build_pruned_dnf_rules_cls(\n",
        "    model: torch.nn.Module,\n",
        "    dataloader,\n",
        "    rules: Dict[int, List[Tuple[int, float]]],\n",
        "    target_layer: torch.nn.Module,\n",
        "    *,\n",
        "    apply_act: bool = False,\n",
        "    min_predicates: int = 3,          # paper’s threshold\n",
        "    min_support: int = 0,\n",
        "    device: str = \"cuda\",\n",
        ") -> Dict[int, List[List[Tuple[int, float]]]]:\n",
        "    \"\"\"\n",
        "    Returns a pruned DNFs rule set using simple positive pruning:\n",
        "        {class_id: [[(idx,thr), …], …]}\n",
        "    \"\"\"\n",
        "    # capture layer‑(l‑1) activations\n",
        "    buf: List[torch.Tensor] = []\n",
        "    def _hook(_, __, out):\n",
        "        buf.append(out.detach().cpu())\n",
        "\n",
        "    h = target_layer.register_forward_hook(_hook)\n",
        "    act_fn: Callable = torch.nn.functional.gelu if apply_act else (lambda x: x)\n",
        "\n",
        "    pattern_counts: Dict[int, Counter] = defaultdict(Counter)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            labels = batch.pop(\"labels\").cpu()\n",
        "            batch  = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "            buf.clear()\n",
        "            model(**batch)\n",
        "            acts = act_fn(buf.pop())\n",
        "            if acts.dim() == 3: # CLS position\n",
        "                acts = acts[:, 0, :]\n",
        "\n",
        "            for i, c in enumerate(labels.tolist()):\n",
        "                active = tuple(\n",
        "                    (idx, thr)\n",
        "                    for idx, thr, *_ in rules.get(c, [])\n",
        "                    if acts[i, idx] >= thr\n",
        "                )\n",
        "                if len(active) >= min_predicates:\n",
        "                    pattern_counts[c][frozenset(active)] += 1\n",
        "\n",
        "    h.remove()\n",
        "    # prune by support\n",
        "    kept: Dict[int, Set[FrozenSet[Tuple[int, float]]]] = defaultdict(set)\n",
        "    for c, counter in pattern_counts.items():\n",
        "        for clause, cnt in counter.items():\n",
        "            if cnt >= min_support:\n",
        "                kept[c].add(clause)\n",
        "\n",
        "    # drop supersets (prune)\n",
        "    pruned_rules: Dict[int, List[List[Tuple[int, float]]]] = {}\n",
        "    for c, clauses in kept.items():\n",
        "        minimal = []\n",
        "        for cl in sorted(clauses, key=len):          # shortest first\n",
        "            if not any(cl > m for m in minimal):\n",
        "                minimal.append(cl)\n",
        "        pruned_rules[c] = [sorted(list(cl)) for cl in minimal]\n",
        "\n",
        "    return pruned_rules\n"
      ],
      "metadata": {
        "id": "EZiZOi3xBcx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grounding (Step 3)"
      ],
      "metadata": {
        "id": "Qa90zFMc9NhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layers = {\n",
        "    \"layer1\" : model.distilbert.transformer.layer[0].output_layer_norm,\n",
        "    \"layer2\" : model.distilbert.transformer.layer[1].output_layer_norm,\n",
        "    \"layer3\" : model.distilbert.transformer.layer[2].output_layer_norm,\n",
        "    \"layer4\" : model.distilbert.transformer.layer[3].output_layer_norm,\n",
        "    \"layer5\" : model.distilbert.transformer.layer[4].output_layer_norm,\n",
        "    \"layer6\" : model.distilbert.transformer.layer[5].output_layer_norm,\n",
        "}"
      ],
      "metadata": {
        "id": "iw90CgQYSXjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from scipy import stats\n",
        "import pandas as pd\n",
        "\n",
        "def _compute_support_table(\n",
        "    *,\n",
        "    flip_counter: dict,\n",
        "    total_counter: dict,\n",
        "    df_counter: dict,\n",
        "    rule_neurons_counter: dict,\n",
        "    n_docs: int,\n",
        "    min_df: int = 3,\n",
        "    alpha: float = 0.05,\n",
        "    min_flips: int = 3\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"Return a DataFrame with one‑tailed significance testing.\n",
        "    \"\"\"\n",
        "\n",
        "    rows = []\n",
        "\n",
        "    global_flips = sum(\n",
        "        cnt for cls_dict in flip_counter.values()\n",
        "        for pred_dict in cls_dict.values()\n",
        "        for cnt in pred_dict.values()\n",
        "    )\n",
        "    global_total = sum(\n",
        "        cnt for cls_tot in total_counter.values()\n",
        "        for cnt in cls_tot.values()\n",
        "    )\n",
        "    p0 = (global_flips + 1e-6) / (global_total + 1e-6)\n",
        "\n",
        "    # iterate over all predicates flips\n",
        "    for cls, tok_dict in flip_counter.items():\n",
        "        for token, pred_dict in tok_dict.items():\n",
        "            df = df_counter[token]\n",
        "            if df < min_df:\n",
        "                continue\n",
        "            idf = math.log((n_docs + 1) / (df + 1))\n",
        "\n",
        "            for ptype, flips in pred_dict.items():\n",
        "                total = total_counter[cls][(token, ptype)]\n",
        "                if total < min_flips:\n",
        "                    continue\n",
        "\n",
        "                p_hat = flips / total\n",
        "\n",
        "                # one tailed z test for significant flips\n",
        "                se = math.sqrt(max(p0 * (1 - p0), 1e-9) / total)\n",
        "                if se == 0:\n",
        "                    continue\n",
        "\n",
        "                z = (p_hat - p0) / se\n",
        "                if z <= 0:\n",
        "                    continue\n",
        "\n",
        "                p_val = 1 - stats.norm.cdf(z)  # one tail\n",
        "                if p_val >= alpha:\n",
        "                    continue\n",
        "\n",
        "                # log‑odds in bits, IDF‑weighted\n",
        "                support_score = 0.5 * idf * math.log2((p_hat + 1e-6) / (p0 + 1e-6))\n",
        "                cnt = rule_neurons_counter.get((cls, token, ptype), {})\n",
        "                for neuron_id, n_flips in cnt.items():\n",
        "                    rows.append(\n",
        "                        dict(\n",
        "                            cls        = cls,\n",
        "                            neuron_id  = neuron_id, # id of the neuron that flipped\n",
        "                            token      = token,\n",
        "                            pred_type  = ptype,\n",
        "                            flips      = n_flips, # neuron‑specific count\n",
        "                            total      = total,\n",
        "                            rate       = p_hat,\n",
        "                            idf        = idf,\n",
        "                            z          = z,\n",
        "                            p_val      = p_val,\n",
        "                            support_score = 0.5 * idf * math.log2((p_hat + 1e-6) /\n",
        "                                                                  (p0 + 1e-6)),\n",
        "                        )\n",
        "                    )\n",
        "\n",
        "    df_out = pd.DataFrame(rows)\n",
        "    # High score => strong enrichment and rarity.\n",
        "    return df_out\n"
      ],
      "metadata": {
        "id": "h6dO5XlNStMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math, string\n",
        "from collections import defaultdict, Counter\n",
        "from typing import Dict, List, Tuple\n",
        "import gc\n",
        "import torch, torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\"])  # load once\n",
        "FLUSH_INTERVAL = 1024\n",
        "@torch.no_grad()\n",
        "def causal_word_lexical_batched(\n",
        "    model,\n",
        "    dataloader,\n",
        "    predicates: Dict[int, List[Tuple[int, float, float]]],\n",
        "    module: torch.nn.Module,\n",
        "    tokenizer,\n",
        "    use_gelu: bool,\n",
        "    *,\n",
        "    support_thr: float = 0.03,\n",
        "    min_df: int = 3,\n",
        "    device: str = \"cuda\",\n",
        "    chunk_size: int = 32,\n",
        "    pos_threshold: float = 0.2,\n",
        "    max_after_tokens: int = 6, # distance cap after/before subj/verb\n",
        ") -> pd.DataFrame:\n",
        "    keyword_counts = defaultdict(Counter)\n",
        "    # polysemantic metric\n",
        "    poly_counts = defaultdict(int)\n",
        "    poly_map = defaultdict(set)\n",
        "    rule_neuron_counter = defaultdict(Counter)\n",
        "    # mapping for neurons\n",
        "    keyword_map  = defaultdict(set)\n",
        "    predtype_map = defaultdict(set)\n",
        "    def _flush(seqs, attns, meta):\n",
        "      if not seqs:\n",
        "          return\n",
        "\n",
        "      inputs = torch.stack(seqs).to(device, non_blocking=True)\n",
        "      masks  = torch.stack(attns).to(device, non_blocking=True)\n",
        "\n",
        "      acts_holder.clear()\n",
        "      _ = model(input_ids=inputs, attention_mask=masks)\n",
        "      cls = acts_holder.pop().cpu()\n",
        "      for j, (c_hat, word, ptype, active) in enumerate(meta):\n",
        "          key = (word, ptype)\n",
        "          total_counter[c_hat][key] += 1\n",
        "\n",
        "          dropped = [i for i, thr in active if cls[j, i] < thr]\n",
        "          if dropped:  # causal flip happened\n",
        "              flip_counter[c_hat][word][ptype] += 1\n",
        "              for i in dropped:\n",
        "                  poly_counts[(i, ptype)] += 1\n",
        "                  keyword_counts[i][word] += 1  # count keyword flips\n",
        "                  rule_neuron_counter[(c_hat, word, ptype)][i] += 1\n",
        "\n",
        "      del inputs, masks, cls\n",
        "      torch.cuda.empty_cache()\n",
        "    # top k neurons per class by purity\n",
        "    n_classes = model.config.num_labels\n",
        "    mask_id   = tokenizer.mask_token_id or tokenizer.unk_token_id\n",
        "    n_classes = model.config.num_labels\n",
        "\n",
        "    flip_counter  = {c: defaultdict(Counter) for c in range(n_classes)}\n",
        "    total_counter = {c: defaultdict(int)      for c in range(n_classes)}\n",
        "    df_counter    = Counter()\n",
        "\n",
        "    acts_holder: List[torch.Tensor] = []\n",
        "\n",
        "    def _hook(_, __, out):\n",
        "        acts_holder.append(\n",
        "            F.gelu(out, approximate=\"none\")[:, 0, :].detach().cpu() if use_gelu\n",
        "            else out[:, 0, :].detach().cpu()\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "    h = module.register_forward_hook(_hook)\n",
        "\n",
        "    model.eval()\n",
        "    model.gradient_checkpointing_disable()\n",
        "    model.config.use_cache = False\n",
        "\n",
        "    N_docs = 0\n",
        "    for batch in dataloader:\n",
        "        batch = {k: v.to(device, non_blocking=True) for k, v in batch.items()}\n",
        "\n",
        "        acts_holder.clear()\n",
        "        logits   = model(**batch).logits\n",
        "        base_cls = acts_holder.pop()\n",
        "        preds    = logits.argmax(-1)\n",
        "        B, T     = batch[\"input_ids\"].shape\n",
        "        attn     = batch[\"attention_mask\"]\n",
        "\n",
        "        dec_texts = tokenizer.batch_decode(batch[\"input_ids\"], skip_special_tokens=True)\n",
        "\n",
        "        masked_inputs_cpu, masked_attn_cpu, meta = [], [], []\n",
        "        metas_for_df = []\n",
        "\n",
        "        for b in range(B):\n",
        "            c_hat  = int(preds[b])\n",
        "            tokseq = batch[\"input_ids\"][b].cpu()\n",
        "            actvec = base_cls[b]\n",
        "\n",
        "            active_neurons = [\n",
        "                (idx, thr) for idx, thr, *_ in predicates.get(c_hat, [])\n",
        "                if actvec[idx] >= thr\n",
        "            ]\n",
        "            if not active_neurons:\n",
        "                continue\n",
        "\n",
        "            doc = nlp(dec_texts[b])\n",
        "\n",
        "            word_ids = tokenizer.word_ids(batch_index=b) if hasattr(tokenizer, \"word_ids\") else None\n",
        "            tokens   = tokenizer.convert_ids_to_tokens(tokseq.tolist(), skip_special_tokens=False)\n",
        "\n",
        "            seen_tokens_in_doc = set()\n",
        "            word_start = 1\n",
        "            while word_start < T:\n",
        "                # go one by one\n",
        "                tok_id = int(tokseq[word_start])\n",
        "\n",
        "                if tok_id == tokenizer.unk_token_id:\n",
        "                    word_start += 1\n",
        "                    continue\n",
        "                if tok_id in (\n",
        "                    tokenizer.pad_token_id,\n",
        "                    tokenizer.sep_token_id,\n",
        "                    getattr(tokenizer, \"eos_token_id\", -1),\n",
        "                ):\n",
        "                    break\n",
        "\n",
        "                if word_ids is not None:\n",
        "                    wid = word_ids[word_start]\n",
        "                    if wid is None:\n",
        "                        word_start += 1\n",
        "                        continue\n",
        "                    word_end = word_start\n",
        "                    while word_end + 1 < T and word_ids[word_end + 1] == wid:\n",
        "                        word_end += 1\n",
        "                    word_idx = wid\n",
        "                else:\n",
        "                    word_end = word_start\n",
        "                    while word_end + 1 < T and tokens[word_end + 1].startswith(\"##\"):\n",
        "                        word_end += 1\n",
        "                    word_idx = len([t for t in tokens[1:word_start] if not t.startswith(\"##\")])\n",
        "\n",
        "                sub_toks = tokens[word_start : word_end + 1]\n",
        "                word_str = \"\".join(\n",
        "                    (\n",
        "                        t[2:] if t.startswith(\"##\")\n",
        "                        else t[1:] if t and t[0] in {\"Ġ\", \"▁\"}\n",
        "                        else t\n",
        "                    )\n",
        "                    for t in sub_toks\n",
        "                ).lower()\n",
        "                if (\n",
        "                    not word_str\n",
        "                    or word_str == tokenizer.unk_token\n",
        "                    or all(ch in string.punctuation for ch in word_str)\n",
        "                ):\n",
        "                    word_start = word_end + 1\n",
        "                    continue\n",
        "\n",
        "                try:\n",
        "                    tok_spacy = doc[word_idx]\n",
        "                except IndexError:\n",
        "                    word_start = word_end + 1\n",
        "                    continue\n",
        "\n",
        "                sent        = tok_spacy.sent\n",
        "                sent_len    = len(sent)\n",
        "                sent_start  = sent.start\n",
        "                pos_in_sent = word_idx - sent_start\n",
        "                frac        = pos_in_sent / sent_len if sent_len else 0.0\n",
        "\n",
        "                subj_pos = min(\n",
        "                    (t.i for t in sent if t.dep_ in {\"nsubj\", \"nsubjpass\"}), default=None\n",
        "                )\n",
        "                verb_pos = min((t.i for t in sent if t.pos_ == \"VERB\"), default=None)\n",
        "                pred_types = set()\n",
        "                pred_types.add(\"exists\")\n",
        "                if frac <= pos_threshold:\n",
        "                    pred_types.add(\"at_start\")\n",
        "                if frac >= 1.0 - pos_threshold:\n",
        "                    pred_types.add(\"at_end\")\n",
        "\n",
        "                # before / after subject\n",
        "                if subj_pos is not None:\n",
        "                    if word_idx > subj_pos and word_idx - subj_pos <= max_after_tokens:\n",
        "                        pred_types.add(\"after_subject\")\n",
        "                    if word_idx < subj_pos and subj_pos - word_idx <= max_after_tokens:\n",
        "                        pred_types.add(\"before_subject\")\n",
        "\n",
        "                # before / after verb\n",
        "                if verb_pos is not None:\n",
        "                    if word_idx > verb_pos and word_idx - verb_pos <= max_after_tokens:\n",
        "                        pred_types.add(\"after_verb\")\n",
        "                    if word_idx < verb_pos and verb_pos - word_idx <= max_after_tokens:\n",
        "                        pred_types.add(\"before_verb\")\n",
        "\n",
        "                # hashtag\n",
        "                if word_str.startswith(\"#\"):\n",
        "                    print(\"exists\")\n",
        "                    pred_types.add(\"is_hashtag\")\n",
        "\n",
        "                for ptype in pred_types:\n",
        "                    # mask\n",
        "                    masked_seq = tokseq.clone()\n",
        "                    masked_seq[word_start : word_end + 1] = mask_id\n",
        "                    masked_inputs_cpu.append(masked_seq)\n",
        "                    masked_attn_cpu.append(attn[b].cpu())\n",
        "                    meta.append((c_hat, word_str, ptype, active_neurons))\n",
        "                    if len(masked_inputs_cpu) == FLUSH_INTERVAL:   # e.g. 16‑32\n",
        "                        _flush(masked_inputs_cpu, masked_attn_cpu, meta)\n",
        "                        masked_inputs_cpu.clear()\n",
        "                        masked_attn_cpu.clear()\n",
        "                        meta.clear()\n",
        "\n",
        "\n",
        "                seen_tokens_in_doc.add(word_str)\n",
        "                word_start = word_end + 1\n",
        "\n",
        "            metas_for_df.append(seen_tokens_in_doc)\n",
        "\n",
        "        for s in metas_for_df:\n",
        "            df_counter.update(s)\n",
        "        N_docs += len(metas_for_df)\n",
        "\n",
        "        if not masked_inputs_cpu:\n",
        "            torch.cuda.empty_cache()\n",
        "            continue\n",
        "\n",
        "        masked_inputs_cpu = torch.stack(masked_inputs_cpu)\n",
        "        masked_attn_cpu   = torch.stack(masked_attn_cpu)\n",
        "\n",
        "        for i in range(0, masked_inputs_cpu.size(0), chunk_size):\n",
        "            slc = slice(i, i + chunk_size)\n",
        "            inputs = masked_inputs_cpu[slc].to(device, non_blocking=True)\n",
        "            attns  = masked_attn_cpu[slc].to(device, non_blocking=True)\n",
        "            _ = model(input_ids=inputs, attention_mask=attns)\n",
        "            chunk_cls    = acts_holder.pop().cpu()\n",
        "            for j, (c_hat, word_str, ptype, active_neurons) in enumerate(meta[slc]):\n",
        "                key = (word_str, ptype)\n",
        "                total_counter[c_hat][key] += 1\n",
        "                dropped = [idx for idx, thr in active_neurons\n",
        "                              if chunk_cls[j, idx] < thr]\n",
        "\n",
        "                if dropped: # at least one causal flip\n",
        "                    flip_counter[c_hat][word_str][ptype] += 1\n",
        "                    for idx in dropped:\n",
        "                        poly_counts[(idx, ptype)] += 1\n",
        "                        keyword_counts[idx][word_str] += 1\n",
        "                        rule_neuron_counter[(c_hat, word_str, ptype)][idx] += 1\n",
        "            del inputs, attns, chunk_cls\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        del logits, base_cls\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    h.remove()\n",
        "\n",
        "    results_df = _compute_support_table(\n",
        "        flip_counter=flip_counter,\n",
        "        total_counter=total_counter,\n",
        "        df_counter=df_counter,\n",
        "        rule_neurons_counter=rule_neuron_counter,\n",
        "        n_docs=N_docs,\n",
        "        min_df=min_df,\n",
        "        alpha=0.05,\n",
        "        min_flips=1,\n",
        "    )\n",
        "\n",
        "    return results_df\n"
      ],
      "metadata": {
        "id": "nsMBhiGDe8Vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positional Bucketing (Heat Map)**"
      ],
      "metadata": {
        "id": "NN0iDWpxTdYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import string\n",
        "from collections import defaultdict, Counter\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def causal_word_buckets_batched(\n",
        "    model,\n",
        "    dataloader,\n",
        "    predicates: Dict[int, List[Tuple[int, float]]],\n",
        "    module: torch.nn.Module,\n",
        "    tokenizer,\n",
        "    use_gelu: bool,\n",
        "    *,\n",
        "    n_buckets: int = 10,\n",
        "    support_thr: float = 0.02,\n",
        "    min_df: int = 1,\n",
        "    device: str = \"cuda\",\n",
        "    chunk_size: int = 24,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Returns a DataFrame with columns:\n",
        "        cls, token, bucket, flips, total, rate, idf\n",
        "    \"\"\"\n",
        "    mask_id = (\n",
        "        tokenizer.mask_token_id\n",
        "        if tokenizer.mask_token_id is not None\n",
        "        else tokenizer.unk_token_id\n",
        "    )\n",
        "    n_classes = model.config.num_labels\n",
        "\n",
        "    flip_counter  = {c: defaultdict(Counter) for c in range(n_classes)}\n",
        "    total_counter = {c: defaultdict(int)      for c in range(n_classes)}\n",
        "    df_counter    = Counter()\n",
        "\n",
        "    # hooks\n",
        "    acts_holder: List[torch.Tensor] = []\n",
        "\n",
        "    def _hook(_, __, out):\n",
        "        if use_gelu:\n",
        "            out = F.gelu(out, approximate=\"none\")\n",
        "        acts_holder.append(out[:, 0, :].detach().cpu())\n",
        "\n",
        "    h = module.register_forward_hook(_hook)\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    model.gradient_checkpointing_disable()\n",
        "    model.config.use_cache = False\n",
        "\n",
        "    N_docs = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            batch = {k: v.to(device, non_blocking=True) for k, v in batch.items()}\n",
        "\n",
        "            # forward on original text\n",
        "            acts_holder.clear()\n",
        "            logits = model(**batch).logits\n",
        "            base_cls = acts_holder.pop()\n",
        "\n",
        "            preds = logits.argmax(-1)\n",
        "            B, T  = batch[\"input_ids\"].shape\n",
        "            attn  = batch[\"attention_mask\"]\n",
        "            seq_len = attn.sum(-1)\n",
        "\n",
        "            def _bucket(pos, seq_l):\n",
        "                return int(math.floor(pos * n_buckets / seq_l))\n",
        "\n",
        "            # build masked variants\n",
        "            masked_inputs_cpu, masked_attn_cpu, meta = [], [], []\n",
        "            metas_for_df = []\n",
        "\n",
        "            for b in range(B):\n",
        "                c_hat  = int(preds[b])\n",
        "                tokseq = batch[\"input_ids\"][b].cpu()\n",
        "                actvec = base_cls[b]\n",
        "                slen   = int(seq_len[b])\n",
        "\n",
        "                class_preds = predicates.get(c_hat, [])\n",
        "                if not class_preds:\n",
        "                    continue\n",
        "                active_neurons = [\n",
        "                    (idx, thr)\n",
        "                    for idx, thr, *_ in class_preds\n",
        "                    if actvec[idx] >= thr\n",
        "                ]\n",
        "                if not active_neurons:\n",
        "                    continue\n",
        "\n",
        "                if hasattr(tokenizer, \"word_ids\"):\n",
        "                    word_id_seq = tokenizer.word_ids(batch_index=b)\n",
        "                else:\n",
        "                    word_id_seq = None\n",
        "                tokens = tokenizer.convert_ids_to_tokens(\n",
        "                    tokseq.tolist(), skip_special_tokens=False,\n",
        "\n",
        "                )\n",
        "\n",
        "                seen_tokens_in_doc = set()\n",
        "                word_start = 1\n",
        "                while word_start < T:\n",
        "                    tok_id = int(tokseq[word_start])\n",
        "                    if tok_id in (\n",
        "                        tokenizer.pad_token_id,\n",
        "                        tokenizer.sep_token_id,\n",
        "                        getattr(tokenizer, \"eos_token_id\", -1),\n",
        "                    ):\n",
        "                        break\n",
        "\n",
        "                    if word_id_seq is not None:\n",
        "                        wid = word_id_seq[word_start]\n",
        "                        if wid is None:\n",
        "                            word_start += 1\n",
        "                            continue\n",
        "                        word_end = word_start\n",
        "                        while word_end + 1 < T and word_id_seq[word_end + 1] == wid:\n",
        "                            word_end += 1\n",
        "                    else:\n",
        "                        word_end = word_start\n",
        "                        while (\n",
        "                            word_end + 1 < T and tokens[word_end + 1].startswith(\"##\")\n",
        "                        ):\n",
        "                            word_end += 1\n",
        "\n",
        "                    sub_toks = tokens[word_start : word_end + 1]\n",
        "                    def _merge_wordpieces(tok_list):\n",
        "                        # merge words\n",
        "                        pieces = []\n",
        "                        for t in tok_list:\n",
        "                            if t.startswith(\"##\"):\n",
        "                                pieces[-1] += t[2:] # continuation\n",
        "                            elif t[0] in {\"Ġ\", \"▁\"}:\n",
        "                                pieces.append(t[1:]) # setence start\n",
        "                            else:\n",
        "                                pieces.append(t) # regular token\n",
        "                        return \"\".join(pieces).lower()\n",
        "\n",
        "                    word_str = _merge_wordpieces(sub_toks)\n",
        "                    if (\n",
        "                        not word_str\n",
        "                        or all(ch in string.punctuation for ch in word_str)\n",
        "                        or word_str == tokenizer.unk_token\n",
        "                    ):\n",
        "                        word_start = word_end + 1\n",
        "                        continue\n",
        "\n",
        "                    masked_seq = tokseq.clone()\n",
        "                    masked_seq[word_start : word_end + 1] = mask_id\n",
        "                    masked_inputs_cpu.append(masked_seq)\n",
        "                    masked_attn_cpu.append(attn[b].cpu())\n",
        "\n",
        "                    bucket_idx = _bucket(word_start, slen)\n",
        "                    meta.append((c_hat, word_str, bucket_idx, active_neurons))\n",
        "                    seen_tokens_in_doc.add(word_str)\n",
        "\n",
        "                    word_start = word_end + 1\n",
        "\n",
        "                metas_for_df.append(seen_tokens_in_doc)\n",
        "\n",
        "            for s in metas_for_df:\n",
        "                for tok in s:\n",
        "                    df_counter[tok] += 1\n",
        "            N_docs += len(metas_for_df)\n",
        "\n",
        "            if not masked_inputs_cpu:\n",
        "                torch.cuda.empty_cache()\n",
        "                continue\n",
        "\n",
        "            masked_inputs_cpu = torch.stack(masked_inputs_cpu)\n",
        "            masked_attn_cpu   = torch.stack(masked_attn_cpu)\n",
        "\n",
        "            # evaluate masked variants in chunks\n",
        "            for i in range(0, masked_inputs_cpu.size(0), chunk_size):\n",
        "                slc = slice(i, i + chunk_size)\n",
        "                inputs = masked_inputs_cpu[slc].to(device, non_blocking=True)\n",
        "                attns  = masked_attn_cpu[slc].to(device, non_blocking=True)\n",
        "\n",
        "                acts_holder.clear()\n",
        "                _ = model(input_ids=inputs, attention_mask=attns)\n",
        "                chunk_cls = acts_holder.pop().cpu()\n",
        "\n",
        "                for j, (c_hat, word_str, bucket_idx, active_neurons) in enumerate(\n",
        "                    meta[slc]\n",
        "                ):\n",
        "                    key = (word_str, bucket_idx)\n",
        "                    total_counter[c_hat][key] += 1\n",
        "                    if any(chunk_cls[j, idx] < thr for idx, thr in active_neurons):\n",
        "                        flip_counter[c_hat][word_str][bucket_idx] += 1\n",
        "\n",
        "                del inputs, attns, chunk_cls\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "            del logits, base_cls\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    h.remove()\n",
        "\n",
        "    # aggregate\n",
        "    rows = []\n",
        "    for c in range(n_classes):\n",
        "        for word_str, buckets in flip_counter[c].items():\n",
        "            df = df_counter[word_str]\n",
        "            if df < min_df:\n",
        "                continue\n",
        "            idf = math.log((N_docs + 1) / (df + 1))\n",
        "            for bucket_idx, flips in buckets.items():\n",
        "                total = total_counter[c][(word_str, bucket_idx)]\n",
        "                if total == 0:\n",
        "                    continue\n",
        "                rate = flips / total\n",
        "                weighted_rate = idf * rate\n",
        "                if weighted_rate < support_thr:\n",
        "                    continue\n",
        "                rows.append(\n",
        "                    dict(\n",
        "                        cls=c,\n",
        "                        token=word_str,\n",
        "                        bucket=bucket_idx,\n",
        "                        flips=flips,\n",
        "                        total=total,\n",
        "                        rate=rate,\n",
        "                        idf=idf,\n",
        "                    )\n",
        "                )\n",
        "\n",
        "    return pd.DataFrame(rows)\n"
      ],
      "metadata": {
        "id": "gzfz_-Qjrsvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_flip_heatmaps(\n",
        "        df: pd.DataFrame,\n",
        "        per_class: bool = True,\n",
        "        top_tokens: int = 40,\n",
        "        cmap: str = \"viridis\",\n",
        "        figsize: tuple = (12, 6),\n",
        "):\n",
        "    grp = [df] if not per_class else [g for _, g in df.groupby(\"cls\")]\n",
        "\n",
        "    for sub in grp:\n",
        "        c = int(sub.cls.iloc[0]) if per_class else None\n",
        "\n",
        "        tok_counts = sub.groupby(\"token\")[\"total\"].sum().sort_values(ascending=False)\n",
        "        kept = tok_counts.head(top_tokens).index\n",
        "        sub   = sub[sub.token.isin(kept)]\n",
        "\n",
        "        heat = (\n",
        "            sub.pivot(index=\"token\", columns=\"offset\", values=\"rate\")\n",
        "               .fillna(0.0)\n",
        "               .loc[lambda x: x.mean(axis=1).sort_values(ascending=False).index]\n",
        "               .sort_index(axis=1)\n",
        "        )\n",
        "\n",
        "        plt.figure(figsize=figsize)\n",
        "        plt.imshow(heat.values, aspect=\"auto\", cmap=cmap, vmin=0.0, vmax=1.0)\n",
        "        plt.colorbar(label=\"flip rate\")\n",
        "        plt.xticks(np.arange(heat.shape[1]), heat.columns, rotation=90)\n",
        "        plt.yticks(np.arange(heat.shape[0]), heat.index)\n",
        "        title = f\"class {label_mapping[c]}\" if per_class else \"all classes\"\n",
        "        plt.title(f\"Flip-rate heat-map: {title}\")\n",
        "        plt.xlabel(\"token position (offset)\")\n",
        "        plt.ylabel(\"token\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "oPTTNeAu__dF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baselines Eval"
      ],
      "metadata": {
        "id": "5vnGBoZodL2U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate Baseline Scores**"
      ],
      "metadata": {
        "id": "B0NuX6HDPX_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# top keywords from each\n",
        "anchors_tokens = [\n",
        "    \"sad\", \"depression\", \"sadness\", \"depressing\", \"sadly\",\n",
        "    \"depressed\", \"heartbreaking\", \"mourn\", \"restless\", \"gloomy\"\n",
        "]\n",
        "\n",
        "emolex_tokens = [\n",
        "    \"depression\", \"bad\", \"lost\", \"terrorism\", \"sadness\",\n",
        "    \"awful\", \"anxiety\", \"depressed\", \"feeling\", \"offended\"\n",
        "]\n",
        "\n",
        "neurologic_tokens = [\n",
        "    \"sad\", \"depression\", \"lost\", \"depressing\", \"sadness\",\n",
        "    \"sadly\", \"mourn\", \"nightmare\", \"anxiety\", \"never\"\n",
        "]\n",
        "\n",
        "rule_sets = {\n",
        "    \"Anchors\": anchors_tokens,\n",
        "    \"EmoLex\":  emolex_tokens,\n",
        "    \"NeuroLogic\": neurologic_tokens,\n",
        "}\n",
        "\n",
        "SADNESS_ID = 3\n",
        "\n",
        "# helpers\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "\n",
        "def make_predict_fn(tokens):\n",
        "    tset = set(t.lower() for t in tokens)\n",
        "    return lambda txt: int(any(tok in txt.lower() for tok in tset))   # 1 if hits\n",
        "\n",
        "predict_fns = {n: make_predict_fn(toks) for n, toks in rule_sets.items()}\n",
        "\n",
        "# evaluate scores\n",
        "y_true = []\n",
        "y_pred = {n: [] for n in rule_sets}\n",
        "\n",
        "for batch in test_loader:\n",
        "    ids    = batch[\"input_ids\"]\n",
        "    labels = batch[\"labels\"]\n",
        "\n",
        "    texts = tok.batch_decode(ids, skip_special_tokens=True)\n",
        "    gold  = (labels == SADNESS_ID).int().tolist()\n",
        "\n",
        "    y_true.extend(gold)\n",
        "    for name, fn in predict_fns.items():\n",
        "        y_pred[name].extend(fn(t) for t in texts)\n",
        "\n",
        "print(f\"{'Model':<10}  P      R      F1     Acc\")\n",
        "for name, preds in y_pred.items():\n",
        "    p, r, f1, _ = precision_recall_fscore_support(\n",
        "        y_true, preds, average=\"binary\", pos_label=1, zero_division=0\n",
        "    )\n",
        "    acc = accuracy_score(y_true, preds)\n",
        "    print(f\"{name:<10}  {p:.3f}  {r:.3f}  {f1:.3f}  {acc:.3f}\")\n"
      ],
      "metadata": {
        "id": "KDN_nWnj6IM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Benchmark EmoLex**"
      ],
      "metadata": {
        "id": "48ofnPAYQntL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import torch, torch.nn.functional as F, numpy as np, pandas as pd, tqdm\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from torch.utils.data import DataLoader\n",
        "from collections import defaultdict, Counter\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# setup\n",
        "MODEL_ID   = \"philschmid/DistilBERT-tweet-eval-emotion\"\n",
        "BATCH_SIZE = 64\n",
        "MAX_LEN    = 128\n",
        "DEVICE     = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# data\n",
        "ds_train = concatenate_datasets([\n",
        "    load_dataset(\"tweet_eval\", \"emotion\", split=\"train\"),\n",
        "    load_dataset(\"tweet_eval\", \"emotion\", split=\"validation\")\n",
        "])\n",
        "ds_test  = load_dataset(\"tweet_eval\", \"emotion\", split=\"test\")\n",
        "\n",
        "tok = AutoTokenizer.from_pretrained(MODEL_ID)\n",
        "\n",
        "def collate(batch):\n",
        "    enc = tok([b[\"text\"] for b in batch],\n",
        "              padding=\"max_length\",\n",
        "              truncation=True,\n",
        "              max_length=MAX_LEN,\n",
        "              return_tensors=\"pt\")\n",
        "    enc[\"labels\"] = torch.tensor([b[\"label\"] for b in batch])\n",
        "    return enc\n",
        "\n",
        "test_loader = DataLoader(ds_test,\n",
        "                         batch_size=BATCH_SIZE,\n",
        "                         shuffle=False,\n",
        "                         collate_fn=collate)\n",
        "\n",
        "# label mapping\n",
        "tmp_model  = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_ID, torch_dtype=torch.float16\n",
        ")\n",
        "id2label   = {int(k): v.lower() for k, v in tmp_model.config.id2label.items()}\n",
        "label2id   = {v: k for k, v in id2label.items()}\n",
        "del tmp_model  # free memory\n",
        "n_labels   = len(id2label)\n",
        "\n",
        "# emolex baseline\n",
        "URL = (\"https://archive.org/download/nrc-emotion-lexicon-v0.92/\"\n",
        "       \"NRC-emotion-lexicon-wordlevel-alphabetized-v0.92.txt\")\n",
        "df = pd.read_csv(URL, sep=\"\\t\", names=[\"word\", \"emotion\", \"flag\"])\n",
        "\n",
        "lex  = defaultdict(list)\n",
        "for w, e, f in df.itertuples(index=False):\n",
        "    if f == 1 and e.lower() in label2id:\n",
        "        lex[w].append(label2id[e.lower()])\n",
        "\n",
        "def emolex_predict(texts):\n",
        "    preds = []\n",
        "    for t in texts:\n",
        "        toks  = re.findall(r\"[a-z]+\", t.lower()) # keep letters only\n",
        "        votes = Counter(em\n",
        "                        for tok in toks\n",
        "                        for em in lex.get(tok, []))\n",
        "        preds.append(None if not votes else votes.most_common(1)[0][0])\n",
        "    return preds\n",
        "\n",
        "# evaluate\n",
        "\n",
        "def evaluate(loader, predict_fn):\n",
        "    correct, total, covered = 0, 0, 0\n",
        "    for batch in tqdm.tqdm(loader, desc=\"eval\", leave=False):\n",
        "        texts   = tok.batch_decode(batch[\"input_ids\"],\n",
        "                                   skip_special_tokens=True)\n",
        "        labels  = batch[\"labels\"].tolist()\n",
        "        outputs = predict_fn(texts)\n",
        "        for g, p in zip(labels, outputs):\n",
        "            total += 1\n",
        "            if p is not None:\n",
        "                covered += 1\n",
        "                if p == g:\n",
        "                    correct += 1\n",
        "    accuracy = correct / covered if covered else 0.0\n",
        "    coverage = covered / total\n",
        "    return accuracy, coverage"
      ],
      "metadata": {
        "id": "fF67idr0dNE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, fn in [(\"EmoLex\", emolex_predict)]:\n",
        "    acc, cov = evaluate(test_loader, fn)\n",
        "    print(f\"{name:8s} | accuracy {acc:.3f} | coverage {cov*100:.1f}%\")"
      ],
      "metadata": {
        "id": "iABl3wQa7S75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EmoLex**"
      ],
      "metadata": {
        "id": "Eow3D0adv9Qc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import defaultdict, Counter\n",
        "class_names = [n.lower() for n in ds_train.features[\"label\"].names]\n",
        "label2id    = {name: i for i, name in enumerate(class_names)}\n",
        "id2label    = {i: name for name, i in label2id.items()}\n",
        "# map nrc emotions to tweeteval\n",
        "emo_map = {\n",
        "    \"anger\":     label2id[\"anger\"],\n",
        "    \"joy\":       label2id[\"joy\"],\n",
        "    \"sadness\":   label2id[\"sadness\"],\n",
        "    # treat anticipation / trust as optimism\n",
        "    \"anticipation\": label2id[\"optimism\"],\n",
        "    \"trust\":        label2id[\"optimism\"],\n",
        "}\n",
        "\n",
        "lex = defaultdict(list)\n",
        "for w, e, f in df.itertuples(index=False):\n",
        "    if f == 1 and e.lower() in emo_map:\n",
        "        lex[w].append(emo_map[e.lower()])\n",
        "\n",
        "_token_re = re.compile(r\"[a-z]+\")\n",
        "\n",
        "\n",
        "def emolex_predict(texts):\n",
        "    out = []\n",
        "    for t in texts:\n",
        "        toks  = _token_re.findall(t.lower()) # strip punctuation\n",
        "        votes = Counter(cls for tok in toks for cls in lex.get(tok, []))\n",
        "        out.append(None if not votes else votes.most_common(1)[0][0])\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "lFgaKaDEvONn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# top-k words\n",
        "import re\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "def emolex_top_rules(texts, lex, id2label, top_k=20):\n",
        "    word_re    = re.compile(r\"[a-z]+\")\n",
        "    cls_counts = defaultdict(Counter)\n",
        "\n",
        "    for txt in texts:\n",
        "        for w in word_re.findall(txt.lower()):\n",
        "            for cls in lex.get(w, []):\n",
        "                cls_counts[cls][w] += 1\n",
        "\n",
        "    for cls, cnt in cls_counts.items():\n",
        "        print(f\"\\nClass {cls} ({id2label[cls]}):\")\n",
        "        for word, freq in cnt.most_common(top_k):\n",
        "            print(f\"{freq:6d}  {word}\")\n",
        "\n",
        "# run it on the TweetEval test texts\n",
        "test_texts = [ex[\"text\"] for ex in ds_test]\n",
        "emolex_top_rules(test_texts, lex, id2label, top_k=20)\n"
      ],
      "metadata": {
        "id": "xeAqplmP6y9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation of DNF Clauses"
      ],
      "metadata": {
        "id": "3nKvWDWHlK2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, List, Tuple\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# rules = {class_id: [[(idx, thr), …], …]}\n",
        "\n",
        "def eval_clauses_individually(\n",
        "    model: torch.nn.Module,\n",
        "    dataloader,\n",
        "    rules: Dict[int, List[List[Tuple[int, float]]]],\n",
        "    target_layer: torch.nn.Module,\n",
        "    *,\n",
        "    apply_act: bool = False,\n",
        "    device: str = \"cuda\",\n",
        "    top_k: int = 1,\n",
        ") -> Dict[int, List[Tuple[List[Tuple[int, float]], float]]]:\n",
        "    buf = []\n",
        "\n",
        "    def _hook(_, __, out):\n",
        "        buf.append(out.detach())\n",
        "\n",
        "    h = target_layer.register_forward_hook(_hook)\n",
        "    act_fn = torch.nn.functional.gelu if apply_act else (lambda x: x)\n",
        "    model.eval()\n",
        "\n",
        "    # cache all activations\n",
        "    acts_all, labels_all = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            labels = batch.pop(\"labels\").cpu()\n",
        "            batch  = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "            buf.clear()\n",
        "            model(**batch)\n",
        "            acts = act_fn(buf.pop()).cpu()\n",
        "            if acts.dim() == 3:\n",
        "                acts = acts[:, 0, :]\n",
        "            acts_all.append(acts)\n",
        "            labels_all.append(labels)\n",
        "    acts_all   = torch.cat(acts_all)\n",
        "    labels_all = torch.cat(labels_all)\n",
        "\n",
        "    results: Dict[int, List[Tuple[List[Tuple[int, float]], float]]] = {}\n",
        "\n",
        "    for class_id, clauses in rules.items():\n",
        "        class_mask = labels_all == class_id\n",
        "        if not class_mask.any():\n",
        "            continue  # no examples of this class in loader\n",
        "\n",
        "        scores = []\n",
        "        for clause in clauses:\n",
        "            # evaluate clause on all samples\n",
        "            fires = torch.ones_like(class_mask, dtype=torch.bool)\n",
        "            for idx, thr in clause:\n",
        "                # all has to fire\n",
        "                fires &= acts_all[:, idx] > thr\n",
        "\n",
        "            # predictions: class_id when fires else -1\n",
        "            correct = (fires & class_mask).sum().item()\n",
        "            total   = class_mask.sum().item()\n",
        "            acc     = correct / total if total else 0.0\n",
        "            scores.append((clause, acc))\n",
        "\n",
        "        # sort by accuracy (desc) then by clause length with shorter prefered\n",
        "        scores.sort(key=lambda x: (-x[1], len(x[0])))\n",
        "        results[class_id] = scores[:top_k]\n",
        "\n",
        "    h.remove()\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "ex5pDf-89rzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, List, Tuple\n",
        "from collections import Counter\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "def eval_pruned_dnf_rules_pos(\n",
        "    model: torch.nn.Module,\n",
        "    dataloader,\n",
        "    rules: Dict[int, List[List[Tuple[int, float]]]],\n",
        "    target_layer: torch.nn.Module,\n",
        "    *,\n",
        "    apply_act: bool = False,\n",
        "    device: str = \"cuda\",\n",
        "    average: str = \"macro\",\n",
        "):\n",
        "    \"\"\"\n",
        "    Evaluate pruned DNF rule‑sets with only positive predicates.\n",
        "    \"\"\"\n",
        "    buf = []\n",
        "\n",
        "    def _hook(_, __, out):\n",
        "        buf.append(out.detach())\n",
        "\n",
        "    h = target_layer.register_forward_hook(_hook)\n",
        "    act_fn = torch.nn.functional.gelu if apply_act else (lambda x: x)\n",
        "\n",
        "    y_true, y_pred = [], []\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            labels = batch.pop(\"labels\").cpu()\n",
        "            batch  = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "            buf.clear()\n",
        "            model(**batch)\n",
        "            acts = act_fn(buf.pop()).cpu()\n",
        "\n",
        "            if acts.dim() == 3:\n",
        "                acts = acts[:, 0, :]\n",
        "\n",
        "            for a, gold in zip(acts, labels):\n",
        "                best_score, best_margin, pred = -1.0, -1.0, -1\n",
        "\n",
        "                for c, clauses in rules.items():\n",
        "                    total = len(clauses)\n",
        "                    fired = []\n",
        "\n",
        "                    for clause in clauses:\n",
        "                        if all(a[idx] > thr for idx, thr in clause):\n",
        "                            fired.append(clause)\n",
        "\n",
        "                    if not fired:\n",
        "                        continue\n",
        "\n",
        "                    hit_rate = len(fired) / total\n",
        "                    margin   = sum(\n",
        "                        sum(a[idx] - thr for idx, thr in clause)\n",
        "                        for clause in fired\n",
        "                    )\n",
        "\n",
        "                    if hit_rate > best_score or (\n",
        "                        hit_rate == best_score and margin > best_margin\n",
        "                    ):\n",
        "                        best_score, best_margin, pred = hit_rate, margin, c\n",
        "\n",
        "                y_true.append(gold.item())\n",
        "                y_pred.append(pred)\n",
        "\n",
        "    h.remove()\n",
        "\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    f1  = f1_score(y_true, y_pred, average=average, zero_division=0)\n",
        "    print(f\"Accuracy: {acc:.4f}   Macro‑F1: {f1:.4f}\")\n",
        "    return acc, f1"
      ],
      "metadata": {
        "id": "lfIC0_cou66E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, List, Tuple\n",
        "from collections import Counter\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def eval_pruned_dnf_rules(\n",
        "    model: torch.nn.Module,\n",
        "    dataloader,\n",
        "    rules,\n",
        "    target_layer: torch.nn.Module,\n",
        "    *,\n",
        "    apply_act: bool = False,\n",
        "    device: str = \"cuda\",\n",
        "    average: str = \"macro\",\n",
        "):\n",
        "    \"\"\"\n",
        "    Evaluate pruned general DNF rule‑sets.\n",
        "    \"\"\"\n",
        "    buf = []\n",
        "\n",
        "    def _hook(_, __, out):\n",
        "        buf.append(out.detach())\n",
        "\n",
        "    h = target_layer.register_forward_hook(_hook)\n",
        "    act_fn = torch.nn.functional.gelu if apply_act else (lambda x: x)\n",
        "\n",
        "    y_true, y_pred = [], []\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            labels = batch.pop(\"labels\").to(\"cpu\")\n",
        "            batch  = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "            buf.clear()\n",
        "            model(**batch)\n",
        "            acts = act_fn(buf.pop().to(\"cpu\"))\n",
        "\n",
        "            if acts.dim() == 3:\n",
        "                acts = acts[:, 0, :]\n",
        "\n",
        "            for a, gold in zip(acts, labels):\n",
        "                best_score, best_margin, pred = -1.0, -1.0, -1\n",
        "\n",
        "                for c, clauses in rules.items():\n",
        "                    total = len(clauses)\n",
        "                    fired_clauses = []\n",
        "\n",
        "                    for clause in clauses:\n",
        "                        if all(\n",
        "                            (a[idx] > thr) if sign else (a[idx] <= thr)\n",
        "                            for idx, thr, sign in clause\n",
        "                        ):\n",
        "                            # all predicates fired so DNF rule fired\n",
        "                            fired_clauses.append(clause)\n",
        "\n",
        "                    if not fired_clauses:\n",
        "                        continue\n",
        "\n",
        "                    hit_rate = len(fired_clauses) / total\n",
        "                    margin   = sum( # tie break\n",
        "                        sum(\n",
        "                            (a[idx] - thr) if sign else (thr - a[idx])\n",
        "                            for idx, thr, sign in clause\n",
        "                        )\n",
        "                        for clause in fired_clauses\n",
        "                    )\n",
        "\n",
        "                    if (\n",
        "                        hit_rate > best_score\n",
        "                        or (hit_rate == best_score and margin > best_margin)\n",
        "                    ):\n",
        "                        best_score, best_margin, pred = hit_rate, margin, c\n",
        "\n",
        "                y_true.append(gold.item())\n",
        "                y_pred.append(pred)\n",
        "\n",
        "    h.remove()\n",
        "\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    f1  = f1_score(y_true, y_pred, average=average, zero_division=0)\n",
        "\n",
        "    print(f\"Accuracy: {acc:.4f}   Macro‑F1: {f1:.4f}\")\n",
        "    return acc, f1"
      ],
      "metadata": {
        "id": "fJ5uBIyYMXHS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}